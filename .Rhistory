knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(stringr)
library(dplyr)
library(magrittr)
library(tokenizers)
library(tidyverse)
library(tidytext)
#library(merTools)
url_soccor = "https://en.wikipedia.org/wiki/FIFA_World_Cup"
page_soccor = url_soccor %>% read_html()
text_soccor = page_soccor%>%html_nodes('p')%>%html_text() #%>%html
text_soccor = gsub("\\[.*?\\]","",text_soccor)
text_soccor = gsub("\n","",text_soccor)
sentences_soccer = tokenize_sentences(text_soccor)
df_soccor = data.frame()
for(sentence in sentences_soccer)
{
df_soccor<-rbind(df_soccor, as.data.frame(sentence, stringsAsFactors = FALSE))
}
df_soccor$category = "soccor"
head(df_soccor)
url_trader = "https://en.wikipedia.org/wiki/Warren_Buffett"
page_trader = url_trader %>% read_html()
text_trader = page_trader%>%html_nodes('p')%>%html_text()
text_trader = gsub("\\[.*?\\]","",text_trader)
text_trader = gsub("\n","",text_trader)
#span.nowrap
text_trader = gsub("\\span.nowrap","",text_trader)
sentences_trader = tokenize_sentences(text_trader)
df_trader = data.frame()
for(sentence in sentences_trader)
{
df_trader<-rbind(df_trader, as.data.frame(sentence, stringsAsFactors = FALSE))
}
df_trader$category = "trader"
head(df_trader)
url_dancer = "https://en.wikipedia.org/wiki/Michael_Jackson"
page_dancer = url_dancer %>% read_html()
text_dancer = page_dancer%>%html_nodes('p')%>%html_text()
text_dancer = gsub("\\[.*?\\]","",text_dancer)
text_dancer = gsub("\n","",text_dancer)
sentences_dancer = tokenize_sentences(text_dancer)
df_dancer = data.frame()
for(sentence in sentences_dancer)
{
df_dancer<-rbind(df_dancer, as.data.frame(sentence, stringsAsFactors = FALSE))
}
df_dancer$category = "dancer"
head(df_dancer)
url_scientist = "https://en.wikipedia.org/wiki/Albert_Einstein"
page_scientist = url_scientist %>% read_html()
text_scientist = page_scientist%>%html_nodes('p')%>%html_text()
text_scientist = gsub("\\[.*?\\]","",text_scientist)
text_scientist = gsub("\n","",text_scientist)
#span.nowrap
text_scientist = gsub("\\span.nowrap","",text_scientist)
sentences_scientist = tokenize_sentences(text_scientist)
df_scientist = data.frame()
for(sentence in sentences_scientist)
{
df_scientist<-rbind(df_scientist, as.data.frame(sentence, stringsAsFactors = FALSE))
}
df_scientist$category = "scientist"
head(df_scientist)
df_combined = rbind(df_soccor, df_trader, df_dancer, df_scientist)
#head(df_combined)
set.seed(39)
shuffled_rows <- sample(nrow(df_combined))
df_shuffled <- df_combined[shuffled_rows, ]
head(df_shuffled)
df_shuffled$doc_id<-NA
numberOfRows = nrow(df_shuffled)
rownumber = 1
while (rownumber <= numberOfRows )
{
df_shuffled[rownumber,]$doc_id<-ceiling(rownumber/8)
rownumber = rownumber+1
}
head(df_shuffled)
by_category = df_shuffled %>% group_by(category) %>%  mutate(document = doc_id) %>% unite(document, category, doc_id)
#by_category
by_category_word = by_category %>% unnest_tokens(word, sentence)
word_counts = by_category_word %>% anti_join(stop_words) %>% count(document, word, sort = TRUE) %>% ungroup()
word_counts
matrix_dtm = word_counts %>%cast_dtm(document, word, n)
matrix_dtm
library(topicmodels)
system.time({
category_lda <- LDA(matrix_dtm, k = 4, control = list(seed = 2468))
})
category_lda
category_topics <- tidy(category_lda, matrix = "beta")
category_topics
top_terms <- category_topics %>%
group_by(topic) %>%
top_n(5, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms
library(ggplot2)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
# 1.soccor
# 2.trader
# 3.dancer
# 4.scientist
category_gamma <- tidy(category_lda, matrix = "gamma")
category_gamma
category_gamma <- category_gamma%>%separate(document, c("category", "document"), sep = "_", convert = TRUE)
category_gamma
category_gamma %>%
mutate(title = reorder(category, gamma * topic)) %>%
ggplot(aes(factor(topic), gamma)) +
geom_boxplot() +
facet_wrap(~ title)
shiny::runApp('TA-Q3/TABA-Q3/TABA-Q3')
runApp('D:/2_p/Jakki_Personnel/Studies/CBA/T1/TA/GroupProject/TA-Q3/Q3')
